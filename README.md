# Local RAG Chatbot with PDF Ingestion

## Overview

This project implements a local Retrieval-Augmented Generation (RAG) chatbot that ingests PDF documents, extracts their content and metadata, and uses Langchain and LangGraph to create a conversational AI. The chatbot allows users to ask questions about the content of the ingested PDFs and receive relevant answers.

## Key Features

-   **PDF Ingestion:** Processes PDF documents to extract text content and metadata.
-   **Markdown Conversion:** Converts PDF content to Markdown format for easier processing.
-   **Metadata Extraction:** Extracts relevant metadata from PDFs to enhance the retrieval process.
-   **Local RAG Implementation:** Utilizes a local RAG setup, ensuring data privacy and control.
-   **Langchain Integration:** Leverages Langchain for document loading, text splitting, and vectorstore management.
-   **LangGraph Implementation:** Employs LangGraph to orchestrate the RAG pipeline and manage conversation flow.
-   **Chat History:** Maintains chat history for contextual conversations.

## File Structure

The project structure is organized as follows:

-   `src/`: Contains the source code for the chatbot.
    -   `frontend.py`: Implements the user interface for uploading PDF files and interacting with the chatbot.
    -   `helper.py`: Initializes logging and defines project paths.
    -   `utils/`: Contains utility modules.
        -   `file_ops.py`: Implements file loading and saving operations.
        -   `index_files.py`: Loads documents and their metadata.
        -   `process_files.py`: Processes uploaded PDFs, extracts text and metadata.
        -   `final_block_rag.py`: Defines data structures for graph state.
        -   `structure_output.py`: Defines the structure for citation objects.
-   `README.md`: This file, providing an overview of the project.
-   `.gitignore`: Specifies intentionally untracked files that Git should ignore.

## Modules Description

-   **`frontend.py`**: This script provides the user interface for interacting with the chatbot. It includes a function `cached_process_files` that handles the upload of PDF files, saves them locally, and calls the backend processing function (`process_uploaded_pdfs`).

-   **`helper.py`**: This script initializes the logger and defines important project paths, such as the project root directory.  It also appends the project root and parent directories to the system path.

-   **`utils/file_ops.py`**: This module provides utility functions for loading and saving text files, ensuring UTF-8 encoding.

-   **`utils/index_files.py`**: This module provides the `load_documents_with_metadata` function, which loads markdown files and their metadata from a specified folder structure, creating Langchain `Document` objects.

-   **`utils/process_files.py`**: This module includes the core function `process_uploaded_pdfs` that converts PDF files to markdown, extracts metadata, and saves the results. It uses a private (self-created) PDF extraction library to convert the PDF (Refer to `pdf_text_extractor`).

-   **`utils/final_block_rag.py`**: Defines the `GraphState` TypedDict, which represents the state of the LangGraph graph, including the question, enhanced question, chat history, documents, and answer.

-   **`utils/structure_output.py`**: Defines the `Citation` Pydantic model for structuring citation information, including document name, number, and page numbers.

## Setup and Installation

1.  **Clone the repository:**

    ```bash
    git clone <repository_url>
    cd <repository_directory>
    ```

2.  **Install dependencies:**

    ```bash
    # Use the `uv` package for installing requirements
    `uv sync` would automatically setup a virtual environment under .venv
    ```

    If you want to do it without `uv`, you will have to use `pip install`. Check for the requirements in `pyproject.toml`.

3.  **Environment Configuration**
    *You will have to create an account with Groq and Gemini. Store the API keys in a local keyvault*

## Usage

1.  **Run the `frontend.py` script:**

    ```bash
    streamlit run src/frontend.py
    ```

2.  **Upload PDF files:**

    Use the user interface to upload the PDF documents you want to ingest.

3.  **Interact with the chatbot:**

    Ask questions related to the content of the uploaded PDFs and receive answers generated by the RAG pipeline.

## Dependencies

-   [Langchain](https://www.langchain.com/): A framework for developing applications powered by language models.
-   [LangGraph](https://python.langchain.com/docs/langgraph): A library for building LLM-powered graphs.
-   [Pymupdf](https://pymupdf.readthedocs.io/en/latest/): A library to programmatically access and manipulate PDF documents.
-   [Streamlit](https://streamlit.io/): An open-source app framework for Machine Learning and Data Science teams.
-   [Pydantic](https://docs.pydantic.dev/): Data validation and settings management using Python type annotations.

## Contributing

Contributions are welcome! Please feel free to submit pull requests or open issues to suggest improvements or report bugs.

## License

[Private License]
